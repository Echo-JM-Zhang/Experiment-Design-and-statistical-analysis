---
title: "Assignment 1 Q2"
author: "Jingmin Zhang (Echo)"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(ggpubr)
library(car)
```

1)
```{r}
data <- read.csv("data.hw1.csv")
attach(data)
model1 <- lm(y~x1..days.+x2..mg.silver.+x1..days.:x2..mg.silver.)
summary(model1)
```
  The estimated coefficients of the regression model $y_i=\beta_0+\beta_1x_{1i}+\beta_2x_{2i}+\beta_3x_{1i}x_{2i}+\epsilon_i$ is:
  $$\hat{\underset{\sim}\beta} = \begin{bmatrix}\
  0.4096\\
  0.0005\\
  -0.0756\\
  0.0003\\
  \end{bmatrix}$$
  
2)
```{r}
summary(model1)
```
$H_0:\beta_1=\beta_2=\beta_3=0$
$H_1:$At least one of the coefficients is not equal to 0
  F statistics to test this hypothesis is 54.02, with degrees of freedom (3, 52). p-value is 5.383e-16, which is smaller than significant level 0.05. Thus, we reject the null hypothesis and the model is useful.

3)
$H_0:\beta_3=0, H_1:\beta_3\not=0$
$\hat{\beta_3}=0.0002518$
$se(\hat{\beta_3})=0.0007682$
test statistics $t=\hat{\beta_3}/se(\hat{\beta_3})=0.328$, degree of freedom is $n-1=56-1=55$.
```{r}
# calculate p-value
p <- 2*pt(0.328, 55, lower.tail = FALSE)
print("p-value is")
p
```
p-value is 0.744, which is greater than significant value $\alpha=0.05$. Thus, we fail to reject the null hypothesis, and $\beta_3$ is not significant. We may exclude the interaction term from the model since the interaction is not significant. The new model is given by $y_i=\beta_0+\beta_1x_{1i}+\beta_2x_{2i}+\epsilon_i$

4)
```{r}
model2 <- lm(y~x1..days.+x2..mg.silver.)
model_red <- lm(y~1)
anova(model_red, model2)
```

$H_0:\beta_1=\beta_2=0$
$H_1:$ at least one of the coefficients is not 0
The F statistic is 82.358, df = (2, 53), and the p-value for F test is smaller than $2.2 \times10^{-16}$, which is smaller than significant level $\alpha=0.05$. Thus, we reject the null hypothesis and conclude that at least one of the coefficient is not 0. The model is useful from the lack of fit test.

5)
```{r}
res.std <- rstandard(model2)
p1 <- ggplot(data)+geom_point(aes(x1..days., res.std))+ylab("standardized residuals")+theme_bw()+geom_abline(slope = 0, intercept = 0, color = "red")
p2 <- ggplot(data)+geom_point(aes(x2..mg.silver., res.std))+ylab("standardized residuals")+theme_bw()+geom_abline(slope = 0, intercept = 0, color = "red")
ggarrange(p1, p2, labels = c("A", "B"), ncol = 2)
```
The standardized residual vs predictor plots are shown above. In both plot, the standardized residuals seem to randomly distributed across x-axis, and there is no distribution pattern. Thus, the linear assumption is met for both predictors.

6)
```{r}
vif(model2)
```

All variance inflation factors are less than 5, so no multicollinearity is detected in our model.